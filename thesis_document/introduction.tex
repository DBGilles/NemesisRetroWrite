
\lstdefinelanguage
   [x64]{Assembler}     % add a "x64" dialect of Assembler
   [x86masm]{Assembler} % based on the "x86masm" dialect
   % with these extra keywords:
   {morekeywords={CDQE,CQO,CMPSQ,CMPXCHG16B,JRCXZ,LODSQ,MOVSXD, %
                  POPFQ,PUSHFQ,SCASQ,STOSQ,IRETQ,RDTSCP,SWAPGS, %
                  rax,rdx,rcx,rbx,rsi,rdi,rsp,rbp, %
                  r8,r8d,r8w,r8b,r9,r9d,r9w,r9b, %
                  r10,r10d,r10w,r10b,r11,r11d,r11w,r11b, %
                  r12,r12d,r12w,r12b,r13,r13d,r13w,r13b, %
                  r14,r14d,r14w,r14b,r15,r15d,r15w,r15b}} % etc.

\chapter{Introduction}
\label{cha:introduction}

\section{Protected Module Architectures}
Because of the increasing popularity of IoT devices more and more embedded computing devices are being connected to the Internet. 
These devices are often more susceptible to being exploited because they support software extensibility. 
Additionally because these devices are connected to a network the risk increases since attacks can be done remotely. 
An important technique for securing such devices is the use of hardware support for virtual memory and processor privilege levels.
The OS can build on this support to isolate a process from any other malicious processes on the device. 
However, this introduces a sizable software layer however which is difficult to get sufficiently secure \cite{psma}.
If the attacker controls the OS then its capabilities for attacking a process on the devices increase considerably. 

Maene et al. state that \textit{the goal of trusted computing is to develop technologies which give users guarantees about the behaviour of the software running on their devices}.
An important aspect of trusted computing is therefore to protect software even when attackers have full control of the system. 
One means of achieving this is through the use of Protected Module Architectures (PMAs). 
These architectures seperate critical components into protected modules, also called enclaves,
that are isolated from one another through hardware \cite{trusted-computing-architectures}.  

A number of Protected Module Architectures (PMAs) have been developed to address this problem, both by researchers and industry. 
% volgende zin trekt mogelijks te veel op zin in nemesis paper
PMAs have been developed for both low-end microcontrollers found in embedded systems \cite{trustlite, smart} as well as high-end processors \cite{isox}.
One architecture developed for embedded systems is Sancus. Sancus is a security architecture that can provide strong isolation guarantees on networked embedded systems, 
and has been implemented on a modified TI MSP430 micro-controller \cite{sancus}. 
At the higher end of the spectrum there is Intel SGX. 
Intel SGX is an extension  added to the Intel architecture that allows applications to instantiate enclaves. 
Enclaves are areas in the application's memory that are protected from access from outside of the enclave, even from 
privileged software such as the OS \cite{SGX}. 

Research has shown that it is still possible to extract information from protected applications in PMAs. In their work Xu et al. \cite{xu} introduce a novel type of side-channel attack 
called controlled-attacks. These attacks are categorized by untrusted operating systems that create side-channels through its extensive control of the system.
The authors were able to leverage the OS's high degree of control over the system to extract large amounts of data from applications which were until 
then safe from side-channel attacks. 

\section{Nemesis}
More recently Van Bulck et al. \cite{Nemesis} developed Nemesis, a controlled-channel attack that leverages the interrupt mechanism to extract sensitive information from 
enclaved applications. The authors were able to exploit timing differences in the latency between the arrival of an interrupt request (IRQ) and the execution of the first instruction in the 
interrupt service routine (ISR). They state that their attack is \textit{based on the key observation that an IRQ during a multi-cycle instruction increases the interrupt 
latency with the number of cycles left to execute}. By carefully and deliberately interrupting a process at the right time the authors were able to infer the duration of the interrupted instruction. 
Potential attackers can use this information to determine where the instruction is situated in the program's control flow. When the instruction is part of a secret-dependent branch the 
attacker is able to infer some information about the secret, successfully leaking sensitive information from the program. Van Bulck et al. \cite{Nemesis} showed that this attack is applicable to 
the whole computing spectrum. They were able to apply their attack to the aforementioned Sancus architecture as well as Intel SGX enclaves.  

Figure \ref{fig:pseudo-assembly} illustrates how such an attack might work with a piece of assembly pseudocode. An attacker who is in control of the OS could carefully interrupt the program right
after the conditional jump at line 5. Depending on the value of register r1 the next interrupted instruction is either the addition instruction at line 4 or the multiplication instruction at line 7. 
By measuring the interrupt latency the attacker can infer which of the two instructions was being executed at the time of the interrupt and, more importantly, infer if the value in register r0 is equal to 0. 

\section{Binary Rewriting}
Binary rewriting is the alteration of a compiled program without having the source code at hand. 
Applications of binary rewriting include observing programs during execution, optimizing programs using run-time patching, and 
hardening applications against attacks. In the case of dynamic binary rewriting the rewriting happens during execution of the program. 
Static binary rewriting, on the other hand, occurs before the binary is executed \cite{rewriting-survey}. 
Binary rewriting tools have been developed for both low-end architectures found in embedded devices \cite{microsbs} as well as high-end architectures found in home computers and servers 
\cite{E9Patch, instruction-punning, Dinesh2020RetroWriteSI}. 

\lstset{language=[x64]Assembler, numbers=left, stepnumber=1, frame=single}
\begin{figure}

    \begin{lstlisting}
	CMP r1, $0
	JEQ .l1
	.l1: 
	ADD r1, r2 		; 1 cycle instruction
	JMP .end
	.l2: 
	MUL r1, r2 		; 2 cycle instruction
	JMP .end
	\end{lstlisting}
	\caption{Assembly pseudo-code with a secret-dependent branch that is vulnerable to Nemesis attack}
	\label{fig:pseudo-assembly}
\end{figure}



\section{Related Work}
\subsubsection{Software-based approaches}

A large number of countermeasures have been proposed for closing timing side-channels. These can broadly be categorized as being either software-based or hardware-based. 
Hardware-based solution are based on modification to the architecture, whereas software-based solutions are implemented at the language level \cite{Barthe}. 

Popular software-based approaches to closing timing-leaks include constant-time policies and the program counter model \cite{Barthe}. 
Constant time policies require that memory access and control-flow should not depend on secret data. 
Unfortunately writing code that adheres to these policies can be difficult since it requires knowledge of the compiler and requires developers to deviate from 
conventional programming practices.
% TODO: doen papers verify-constant-time en barthe wat ik zeg hieronder? 
A number of solutions have been proposed to verify if a program adheres to constant-time policies \cite{verify-constant-time, Barthe}.


Molnar et al. \cite{programcounter} first introduced the program counter model in their work, proposing methods for the detection and mitigation of control-flow side channel attacks. 
The authors consider the case where an adversary is able to make an observation of a side channel at each step of the computation. 
The result is a sequence of observations $T= (T_1, T_2, ... T_n)$ called a \textit{transcript}.
The \textit{program counter model} or \textit{PC model} is then the model where each value of the transcript is the processor's program counter during the computation. 
A program is then said to be  PC-secure if the program if this transcript is secure. 
The authors state that \textit{any program that is PC-secure will also be secure against timing attacks}.
Based on this definition of PC-security the authors introduce a code transformation for creating PC-secure C code.
The authors note that they made a number of assumptions in their work. Although these assumptions do not hold for a number of architectures the authors are confident 
that they are reasonable for some embedded devices. 	

%\subsubsection{Automated if-conversion}
%"Moreover, if-conversion comes with a significant performance overhead [12] that somewhat invalidates the
%PMA promise of native code execution in a protected environment." -- Nemesis 
%
%
%
%
%\textbf{TODO: iets over constant time policies}
%%Commonly used software-based approaches to mitigating timing-based side-channel attacks are the program counter and constant-time policies \cite{Barthe}.
 

\subsubsection{Hardware-based approaches}
An orthogonal approach is to close timing leaks using hardware-based solutions. 
Recently Busi et al. \cite{busi} proposed an approach to extend architectures with non-interruptible enclaved execution such that they can also support interruptions without breaking 
the existing isolation properties. Based on this approach they proposed  a design for interruptible enclaves that are resistent against interrupt attacks. 
This design is based on an earlier version of Sancus with non-interruptible enclaves. They modify the architecture to add padding cycles whenever the enclave is interrupted, effectively closing timing leaks. 

A limitation of their approach is that their design is based on the assumption that the timing of instruction is predictable. This is generally not the case for more complex architectures such as Intel's x86\_64.
Additionally their approach requires hardware modifications which means it cannot be applied to off-the-shelf and existing devices. 

%\subsubsection{Beetze.de}
	
\section{Thesis Goal and Outline}
This paper presents a novel algorithm for automatically transforming a program in order to remove any timing leaks. It achieves this by addressing the core cause of the vulnerability: differences in 
latencies between corresponding instructions in secret-dependent branches. Corresponding instructions are instructions that are the same distance away from a branching instruction. 
The proposed algorithm inserts additional instructions such that all corresponding instructions have the same latency without changing affecting the program output. 

The main contributions of this paper are:
\begin{enumerate}
\item The paper presents a novel algorithm for automatically transforming a program to remove any timing leaks.
\item The paper presents an implementation of this algorithm for the Intel x86-64 architecture. 
\item The paper presents an evaluation of the algorithm based on a suite of benchmark programs. 
\end{enumerate}

